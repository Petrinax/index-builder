version: '3.8'

services:

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - stock-data-network
    restart: unless-stopped

  # SQLite storage container
  sqlite:
    image: alpine
    container_name: sqlite_storage
    volumes:
      - ./data:/data
    command: [ "tail", "-f", "/dev/null" ]  # keep container alive
    networks:
      - stock-data-network
    restart: always

  # FastAPI application
  fastapi-app:
    build:
      context: .
      dockerfile: fast_app/Dockerfile
    container_name: fastapi-app
    ports:
      - "8000:8000"
    volumes:
      # Mount data directory to access SQLite database
      - ./data:/app/data
      # Mount logs directory
      - ./logs:/app/logs
      # Mount exports directory
      - ./fast_app/exports:/app/fast_app/exports
    environment:
      - DB_TYPE=${DB_TYPE:-sqlite}
      - DB_PATH=/app/data/stock_data.db
      - DEBUG=${DEBUG:-FALSE}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_TTL=600
      - EXPORT_DIR=/app/fast_app/exports
    depends_on:
      - redis
      - sqlite
    networks:
      - stock-data-network
    restart: unless-stopped

  # Cron job service for daily stock data ingestion
  data-pipeline-cron:
    build:
      context: .
      dockerfile: data_pipeline/Dockerfile.cron
    container_name: data-pipeline-cron
    restart: unless-stopped
    volumes:
      # Mount data directory to persist database
      - ./data:/app/data
      # Mount logs directory to persist logs
      - ./logs:/app/logs
    environment:
      - DATA_PROVIDER=${DATA_PROVIDER:-yfinance}
      - DB_TYPE=${DB_TYPE:-sqlite}
      - DB_PATH=/app/data/stock_data.db
      - MAX_WORKERS=${MAX_WORKERS:-15}
      - TZ=America/New_York # Set timezone for cron jobs
    depends_on:
      - sqlite
    networks:
      - stock-data-network

  # Optional: One-time runner service for manual execution
#  data-pipeline-manual:
#    build:
#      context: .
#      dockerfile: data_pipeline/Dockerfile
#    container_name: data-pipeline-manual
#    profiles:
#      - manual
#    volumes:
#      - ./data:/app/data
#      - ./logs:/app/logs
#      - ./csv_exports:/app/csv_exports
#    environment:
#      - DATA_PROVIDER=${DATA_PROVIDER:-yfinance}
#      - DB_TYPE=${DB_TYPE:-sqlite}
#      - DB_PATH=/app/data/stock_data.db
#      - MAX_WORKERS=${MAX_WORKERS:-15}
#    depends_on:
#      - sqlite
#    networks:
#      - stock-data-network

volumes:
  redis_data:

networks:
  stock-data-network:
    driver: bridge
