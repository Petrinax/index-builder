version: '3.8'

services:
  # Cron job service for daily stock data ingestion
  stock-data-cron:
    build:
      context: .
      dockerfile: data_pipeline/Dockerfile.cron
    container_name: stock-data-cron
    restart: unless-stopped
    volumes:
      # Mount data directory to persist database
      - ./data:/app/data
      # Mount logs directory to persist logs
      - ./logs:/app/logs
      # Mount csv exports directory
      - ./csv_exports:/app/csv_exports
      # Mount env file for configuration
      - ./.env:/app/.env
    environment:
      - DATA_PROVIDER=${DATA_PROVIDER:-yfinance}
      - DB_TYPE=${DB_TYPE:-sqlite}
      - MAX_WORKERS=${MAX_WORKERS:-15}
      - TZ=Asia/Kolkata
    networks:
      - stock-data-network

  # Optional: One-time runner service for manual execution
  stock-data-runner:
    build:
      context: .
      dockerfile: data_pipeline/Dockerfile
    container_name: stock-data-runner
    profiles:
      - manual
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./csv_exports:/app/csv_exports
      - ./.env:/app/.env
    environment:
      - DATA_PROVIDER=${DATA_PROVIDER:-yfinance}
      - DB_TYPE=${DB_TYPE:-sqlite}
      - DB_PATH=/data/stock_data.db
      - MAX_WORKERS=${MAX_WORKERS:-15}
    networks:
      - stock-data-network

    # sqlite is just a file â€” we can use a tiny Alpine image as a "host"
  sqlite:
    image: alpine
    container_name: sqlite_storage
    volumes:
      - ./data:/data
    command: [ "tail", "-f", "/dev/null" ]  # keep container alive
    restart: always

#  sqlite-server:
#    image: coleifer/sqlite-web
#    container_name: sqlite_server
#    volumes:
#      - ./data:/data
#    environment:
#      SQLITE_DATABASE: stock_data.db
#    ports:
#      - "8080:8080"
#    restart: unless-stopped

networks:
  stock-data-network:
    driver: bridge
